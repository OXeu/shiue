---
title: "è‡ªå·±å®ç°é»‘ç™½å›¾ç‰‡è‡ªåŠ¨ä¸Šè‰²AI - ä»åˆå­¦è€…è§’åº¦çš„äºŒæ¬¡è§£è¯»"
date: 2022-10-28T22:25:58+08:00
description: "å¯¹æˆ‘æœºå™¨å­¦ä¹ å…¥é—¨çš„ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œä»åˆå­¦è€…è§’åº¦æœ‰ç–‘æƒ‘çš„å†…å®¹è¿›è¡Œè§£è¯»"
slug: ai-image-colorization
image: deepmind-D_YZmKGSyic-unsplash.jpg
categories:
- AI
tags:
- AI
- Image
- Colorization
draft: false
---

> å°é¢æ¥æº [Unsplash](https://unsplash.com/photos/D_YZmKGSyic)

## å‰è¨€

è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘ç¬¬ä¸€æ¬¡ï¼ˆå‡†ç¡®æ¥è¯´å¯èƒ½æ˜¯ç¬¬äºŒæ¬¡ï¼Œç¬¬ä¸€æ¬¡æ¥è§¦çš„æ˜¯KMeansèšç±»ç®—æ³•ï¼Œä½†æœªæ·±å…¥å­¦ä¹ ï¼‰æ¥è§¦AIæ‰€é˜…è¯»çš„æ–‡ç« ï¼ŒåŸæ–‡å…¶å®å·²ç»ååˆ†è¯¦å®äº†ï¼Œä½†æ˜¯å¯¹äºåˆå­¦è€…ï¼ˆæˆ‘ï¼‰æ¥è¯´è¿˜æ˜¯æœ‰å¾ˆå¤šå½“æ—¶å¹¶ä¸ç†è§£çš„åœ°æ–¹ï¼Œè€Œä¸”åŸæ–‡æ²¡æœ‰ä»»ä½•æ‹“å±•é˜…è¯»ä»¥åŠå‚è€ƒæ–‡çŒ®ï¼Œå¯¼è‡´æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹å¼‚å¸¸è‰°éš¾ï¼Œåªèƒ½è‡ªå·±å»é—®èº«è¾¹çš„å¤§ä½¬æˆ–è€…æ‰¾paperæ¥çœ‹ã€‚ä¸‹é¢å¯¹è¯¥ç¯‡æ–‡ç« ä»åˆå­¦è€…çš„è§’åº¦å¯¹ä¸€äº›å†…å®¹ä½œä¸€äº›æˆ‘ä»»åŠ¡å¿…è¦çš„æ³¨é‡Šã€‚

æ‰€æœ‰ä»£ç æˆ‘å·²ä¸Šä¼ åˆ°Githubï¼š[ThankRain/image_render: ğŸ¨é»‘ç™½å›¾ç‰‡ä¸Šè‰² (github.com)](https://github.com/ThankRain/image_render/tree/dev)

> æœ¬æ–‡æŒ‡çš„åˆå­¦è€…ä¸ºä»æœªæ¥è§¦è¿‡AIç›¸å…³å†…å®¹ä½†æœ‰PythonåŸºæœ¬çš„è¯­æ³•åŸºç¡€

> ç®€å•æè¦ï¼šæœ¬æ–‡æ¶‰åŠåˆ°çš„å†…å®¹æœ‰ï¼šPythonã€TensorFlowã€U-Netæ¨¡å‹

> å¼ºçƒˆå»ºè®®å®‰è£…[Anaconda](https://www.anaconda.com/)ç”¨äºPythonçš„ç‰ˆæœ¬ç®¡ç†
>
> ä¸ºäº†æ›´å¥½çš„è®­ç»ƒæ¨¡å‹ï¼Œå»ºè®®æœ‰ NVIDIA æ˜¾å¡çš„åŒå­¦å…ˆå­¦ä¹ å¦‚ä½•[åœ¨TensorFlowä¸­ä½¿ç”¨GPU](https://tensorflow.google.cn/install/gpu?hl=zh-cn)

## å…³äºæ¨¡å‹

æ–‡ç« å®šä¹‰äº†ä»¥ä¸‹æ¨¡å‹ï¼š

```python
def build_model():
    model = Sequential()
    model.add(InputLayer(input_shape=(None, None, 1)))
    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))
    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))
    model.compile(optimizer='rmsprop', loss='mse')
    return model
```

æ–‡ç« å¹¶æœªå¯¹å…¶è¿›è¡Œè§£é‡Šï¼Œåªæœ‰ä¸€å¥ï¼š

> æ•´ä¸ªè¿‡ç¨‹éå¸¸ç®€å•ï¼Œä¹Ÿä¸æ„§æ˜¯æˆ‘ä»¬çš„simpleç‰ˆæœ¬ï¼Œç›¸ä¿¡ä½ åº”è¯¥ä¸€ç›®äº†ç„¶ã€‚å¦‚æœä½ è§‰å¾—è¿‡äºç®€å•ï¼Œé‚£ä¹ˆåé¢ä¼šæœ‰æ›´åŠ å¤æ‚çš„ç‰ˆæœ¬ã€‚æˆ‘ä»¬è®­ç»ƒ6000æ¬¡ï¼ŒåŒæ—¶æŠŠæ¨¡å‹ä¿å­˜ä¸€ä¸‹ï¼Œåé¢å†é¢„æµ‹çš„æ—¶å€™ä¼šloadæ•´ä¸ªæ¨¡å‹ã€‚

å½“æ—¶æˆ‘çœ‹åˆ°è¿™å¥è¯çš„è¡¨æƒ…æ˜¯è¿™æ ·çš„ï¼š

![ä¸€ç›®äº†ç„¶ï¼Ÿè°ä¸€ç›®äº†ç„¶ï¼Ÿä¸€ç›®äº†ç„¶ä»€ä¹ˆï¼Ÿ](https://n.sinaimg.cn/translate/281/w640h441/20181219/2yu6-hqnkypq9935219.jpg)

é¦–å…ˆï¼Œæˆ‘å°è¯•ä»ä»£ç çš„è§’åº¦æ¥ç†è§£è¿™ä¸ªæ¨¡å‹ï¼šé€šè¿‡å¤šæ¬¡é€æ¸å¢åŠ å·ç§¯æ·±åº¦çš„å·ç§¯ï¼Œéšåè¿›è¡Œåå‘çš„ä¸Šé‡‡æ ·å’Œåå‘å·ç§¯ï¼Œæœ€åè®¾ç½®ä¸€ä¸‹ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ã€‚æ¨¡å‹çš„å¤§æ¦‚æ„æ€å°±æ˜¯è¿™æ ·ï¼Œå…·ä½“å¯ä»¥å»æœæœ Conv2D å’Œ UpSampling2Dï¼Œè¿™é‡Œä¸åšè¿‡å¤šè§£é‡Šã€‚ä½†é—®é¢˜æ˜¯ï¼Œä¸ºä»€ä¹ˆè¦è¿™ä¹ˆå¹²ï¼Ÿæˆ‘ä¸æ˜ç™½ï¼ŒåŸä½œè€…è¯´äº†ï¼š`ä¸€ç›®äº†ç„¶`

## é—®é¢˜1ï¼šä»€ä¹ˆæ˜¯å·ç§¯

ä¸æ˜ç™½ï¼Œé¦–å…ˆå¾—å»æ‰¾ï¼Œè™½ç„¶æˆ‘çŸ¥é“å·ç§¯å‡½æ•°æ˜¯ä»€ä¹ˆï¼Œä½†æ˜¯æˆ‘å®Œå…¨æ— æ³•ä¸è¿™é‡Œçš„å·ç§¯è”ç³»èµ·æ¥ï¼Œé‚£å°±å…ˆå»æŠŠå·ç§¯ææ˜ç™½ã€‚è¿™ä¸ªè§†é¢‘åŸºæœ¬ä¸Šèƒ½å¤Ÿè§£å†³æˆ‘çš„ç¬¬ä¸€ä¸ªé—®é¢˜

[ä»â€œå·ç§¯â€ã€åˆ°â€œå›¾åƒå·ç§¯æ“ä½œâ€ã€å†åˆ°â€œå·ç§¯ç¥ç»ç½‘ç»œâ€ï¼Œâ€œå·ç§¯â€æ„ä¹‰çš„3æ¬¡æ”¹å˜](https://www.bilibili.com/video/BV1VV411478E)

`BV1VV411478E`

ç®€å•æ¥è¯´ï¼Œç¥ç»ç½‘ç»œé‡Œçš„å·ç§¯å°±æ˜¯ä¸€ä¸ªæå–ç‰¹å¾çš„å·¥å…·ï¼Œä½†æ˜¯Conv2Då‡½æ•°ä¸­åªå®šä¹‰äº†å·ç§¯æ ¸çš„å¤§å°è€Œæ²¡æœ‰å®šä¹‰å·ç§¯æ ¸çš„å…·ä½“å€¼ï¼Œåœ¨æˆ‘çš„ç†è§£ä¸­ï¼Œå·ç§¯æ ¸çš„å…·ä½“å€¼ä¾¿æ˜¯æ¨¡å‹éœ€è¦å»å­¦ä¹ çš„å†…å®¹ï¼Œé€šè¿‡ä¸æ–­æ”¹å˜å·ç§¯æ ¸æ¥æå–å›¾åƒçš„ä¸åŒç‰¹å¾ï¼Œæœ€ç»ˆè¾¾åˆ°æˆ‘ä»¬æ‰€éœ€æ±‚çš„å›¾åƒç‰¹å¾ã€‚

## é—®é¢˜2ï¼šè¿™ä¸ªæ¨¡å‹çš„ç®—æ³•å«ä»€ä¹ˆ

è™½ç„¶ç®€å•çŸ¥é“äº†å·ç§¯çš„åŸç†ï¼Œä½†æ˜¯æˆ‘ä»æ—§ä¸æ˜ç™½ä¸ºä»€ä¹ˆæ¨¡å‹è¦è¿™ä¹ˆå†™ã€‚ç»ˆäºï¼Œåœ¨æˆ‘ç¿»é˜…å¤šç¯‡åšå®¢å’ŒPaperä»¥åï¼Œç»ˆäºåœ¨è¿™ç¯‡Paperä¸­ï¼ˆ[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)ï¼‰æ‰¾åˆ°äº†è¿™ä¸ªæ¨¡å‹çš„åå­—ï¼šU-Netï¼ˆUå‹ç½‘ï¼‰

æ›´å¤šå…·ä½“çš„ç»†èŠ‚å¯ä»¥å»æœä¸€ä¸‹åˆ«çš„å¤§ä½¬å†™çš„æ–‡ç« ï¼Œä»¥åŠæœ€åˆæå‡ºU-Netçš„Paperï¼ˆ[[1505.04597\] U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)ï¼‰ï¼Œä¸è¿‡U - Netå·¥ä½œåŸç†ç›®å‰æˆ‘ä¹Ÿä¸æ˜¯ç‰¹åˆ«æ¸…æ™°ï¼Œå°±æš‚ä¸è¿›è¡Œè§£è¯»äº†ï¼Œæœ‰å…´è¶£çš„UUå¯ä»¥è‡ªè¡Œç ”ç©¶ã€‚![U-Netç»“æ„](C:\Users\15738\AppData\Roaming\Typora\typora-user-images\image-20221028214122098.png)



## é—®é¢˜3ï¼šå¤šå›¾ç‰‡é›†å¦‚ä½•è®­ç»ƒ

åŸæ–‡çš„è®­ç»ƒé›†åªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œå¯¼è‡´æœ€ç»ˆè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹åªèƒ½é¢„æµ‹è¯¥å›¾ç‰‡ï¼Œå½“æˆ‘æƒ³è¦å–‚å¤šå¼ å›¾ç‰‡ç»™æ¨¡å‹çš„æ—¶å€™é‡åˆ°äº†å¾ˆå¤šå›°éš¾ï¼ˆåˆå­¦å¯¹æ¡†æ¶å’Œæ¨¡å‹çš„å·¥ä½œåŸç†éƒ½ä¸æ¸…æ™°ï¼Œåªèƒ½æ…¢æ…¢å°è¯•ï¼‰

é¦–å…ˆå°±æ˜¯è¯¥æ¨¡å‹é™åˆ¶äº†å›¾ç‰‡çš„å°ºå¯¸ï¼Œä¸åŒå°ºå¯¸çš„å›¾ç‰‡æ— æ³•æŠ•å–‚ï¼Œå› æ­¤æˆ‘åœ¨è·å–è®­ç»ƒé›†çš„ä»£ç ä¸ŠåŠ å…¥äº†è·å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å›¾ç‰‡&é‡æ–°Resizeå›¾ç‰‡ä¸ºæŒ‡å®šå°ºå¯¸ï¼š

```python
import os

import numpy as np
from keras.layers import Conv2D, UpSampling2D, InputLayer
from keras.models import Sequential
from keras.utils import img_to_array, load_img
from matplotlib import pyplot
from skimage.color import rgb2gray, rgb2lab, lab2rgb
from skimage.io import imsave
h = 272#è®­ç»ƒæ•°æ®é›†å›¾ç‰‡é«˜åº¦
w = 184#è®­ç»ƒæ•°æ®é›†å›¾ç‰‡é«˜åº¦
oh = h#ä¸Šè‰²æµ‹è¯•å›¾ç‰‡é«˜åº¦
ow = w#ä¸Šè‰²æµ‹è¯•å›¾ç‰‡å®½åº¦ï¼Œå°½é‡ä¸è®­ç»ƒå°ºå¯¸ä¿æŒä¸€è‡´ï¼Œå¦åˆ™ä¸Šè‰²æ•ˆæœä¼šå¾ˆå·®
from skimage.transform import resize
# è·å–è®­ç»ƒç”¨å›¾ç‰‡æ•°æ®é›†
def get_trains():
    path = "data/Train"  # æ–‡ä»¶å¤¹ç›®å½•
    files = os.listdir(path)  # å¾—åˆ°æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åç§°
    xx = np.empty((file_count(), w, h, 1))
    yy = np.empty((file_count(), w, h, 2))
    i = 0
    for file in files:  # éå†æ–‡ä»¶å¤¹
        if not os.path.isdir(file):  # åˆ¤æ–­æ˜¯å¦æ˜¯æ–‡ä»¶å¤¹ï¼Œä¸æ˜¯æ–‡ä»¶å¤¹æ‰æ‰“å¼€
            # img
            print(path + "/" + file)  # æ‰“å°ç»“æœ
            image = img_to_array(load_img(path + "/" + file))
            dst_size = (w, h)
            image = resize(image, dst_size)
            image_shape = image.shape
            x = rgb2lab(1.0 / 255 * image)[:, :, 0]
            y = rgb2lab(1.0 / 255 * image)[:, :, 1:]
            y /= 128
            x = x.reshape(image_shape[0], image_shape[1], 1)
            y = y.reshape(image_shape[0], image_shape[1], 2)
            xx[i] = x
            yy[i] = y
            i += 1
    return xx, yy
```

è·å–éªŒè¯æ•°æ®é›†ï¼ˆè¿™é‡Œçš„éªŒè¯æ•°æ®é›†ä¸è®­ç»ƒæ•°æ®é›†ç›¸åŒï¼Œæœªå•ç‹¬ä½¿ç”¨ä¸åŒçš„æµ‹è¯•æ•°æ®é›†ï¼‰ï¼š

```python
def get_trains_origin():
    path = "data/Train"  # æ–‡ä»¶å¤¹ç›®å½•
    files = os.listdir(path)  # å¾—åˆ°æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åç§°
    xx = np.empty((file_count(), ow, oh, 1))
    yy = np.empty((file_count(), ow, oh, 2))
    i = 0
    for file in files:  # éå†æ–‡ä»¶å¤¹
        if not os.path.isdir(file):  # åˆ¤æ–­æ˜¯å¦æ˜¯æ–‡ä»¶å¤¹ï¼Œä¸æ˜¯æ–‡ä»¶å¤¹æ‰æ‰“å¼€
            # img
            print(path + "/" + file)  # æ‰“å°ç»“æœ
            image = img_to_array(load_img(path + "/" + file))
            dst_size = (ow, oh)
            image = resize(image, dst_size)
            image_shape = image.shape
            x = rgb2lab(1.0 / 255 * image)[:, :, 0]
            y = rgb2lab(1.0 / 255 * image)[:, :, 1:]
            y /= 128
            x = x.reshape(image_shape[0], image_shape[1], 1)
            y = y.reshape(image_shape[0], image_shape[1], 2)
            xx[i] = x
            yy[i] = y
            i += 1
    return xx, yy
```



æ¨¡å‹å‡½æ•°åŸºæœ¬æœªä½œä¿®æ”¹ï¼ŒåªåŠ å…¥äº†å®½é«˜é™åˆ¶ï¼ˆä¹Ÿå¯ä»¥ç”¨Noneå»æ‰ï¼Œç”¨é€”ä¸å¤§ä½†æ‡’å¾—ä¿®æ”¹ï¼‰

```python
def build_model(hh,ww):
    model = Sequential()
    model.add(InputLayer(input_shape=(ww, hh, 1)))
    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))
    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))
    model.add(UpSampling2D((2, 2)))
    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))
    model.compile(optimizer='rmsprop', loss='mse')
    return model
```

è®­ç»ƒå‡½æ•°ä¿®æ”¹ä¸ºï¼š

```python
def train():
    xx, yy = get_trains()
    model0 = build_model(h,w)
    num_epochs = 6000
    batch_size = 6
    model_file = 'simple_model.h5'
    model0.load_weights(model_file)
    print(xx.shape,yy.shape)
    print(h,w)
    model0.fit(xx, yy, batch_size=file_count(), epochs=10000)
    model0.save(model_file)
```

ä¸Šè‰²å‡½æ•°ï¼š

```python
def colorize():
    x, y = get_trains_origin()
    model = build_model(oh,ow)
    model.load_weights('simple_model.h5')
    output = model.predict(x)
    print(output.shape, x.shape, y.shape)
    output *= 128
    for i in range(file_count()) :
        tmp = np.zeros((ow, oh, 3))
        tmp[:, :, 0] = x[i, :, :, 0]
        tmp[:, :, 1:] = output[i,:, :, :]
        imsave("test_image_result.png", lab2rgb(tmp))
        imsave("test_image_gray.png", rgb2gray(lab2rgb(tmp)))
        pyplot.imshow(lab2rgb(tmp))
        pyplot.show()
```

æœ€ç»ˆè®­ç»ƒæ•ˆæœå›¾ï¼ˆè¯·è‡ªè¡Œè„‘è¡¥ç°åº¦å›¾ï¼‰ï¼š

![1](1.png)![2](2.png)![3](3.png)![4](4.png)![5](5.png)![6](6.png)![7](7.png)![8](8.png)

è¿™é‡Œåªç®€å•æ‘˜äº†å‡ å¼ å›¾ç‰‡ã€‚ç”±äºæ€§èƒ½é—®é¢˜ï¼Œè®­ç»ƒçš„å›¾ç‰‡å¤§å°éƒ½æ¯”è¾ƒå°ï¼Œçœ‹ç€æ¯”è¾ƒæ¨¡ç³Šï¼Œä½†æ•´ä½“æ•ˆæœä¸é”™ã€‚

å®Œæ•´ä»£ç ï¼š

[ThankRain/image_render: ğŸ¨é»‘ç™½å›¾ç‰‡ä¸Šè‰² (github.com)](https://github.com/ThankRain/image_render)

åœ¨ Colab ä¸­æ‰“å¼€ï¼ˆç”±äºé‡Œé¢åŒ…å«æœ‰24å¼ ä¸Šè‰²ç»“æœå›¾ç‰‡å¯¼è‡´æ–‡ä»¶è¾ƒå¤§ï¼ŒåŠ è½½å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼‰ï¼š

[index.ipynb - Colaboratory (google.com)](https://colab.research.google.com/github/ThankRain/image_render/blob/38e155937805b7269d05655cf204a624e8ac943b/index.ipynb#scrollTo=TrVudyZ16w9v)

## å‚è€ƒæ–‡çŒ®

1. [è‡ªå·±å®ç°é»‘ç™½å›¾ç‰‡è‡ªåŠ¨ä¸Šè‰²AIï¼ˆä¸€ï¼‰ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/30493746)

2. [[1703.10593\] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (arxiv.org)](https://arxiv.org/abs/1703.10593)
3. [[1505.04597\] U-Net: Convolutional Networks for Biomedical Image Segmentation (arxiv.org)](https://arxiv.org/abs/1505.04597)
4. [junyanz/pytorch-CycleGAN-and-pix2pix: Image-to-Image Translation in PyTorch (github.com)](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
5. [ä»â€œå·ç§¯â€ã€åˆ°â€œå›¾åƒå·ç§¯æ“ä½œâ€ã€å†åˆ°â€œå·ç§¯ç¥ç»ç½‘ç»œâ€ï¼Œâ€œå·ç§¯â€æ„ä¹‰çš„3æ¬¡æ”¹å˜ (bilibili.com)](https://www.bilibili.com/video/BV1VV411478E)